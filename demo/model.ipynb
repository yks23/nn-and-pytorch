{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a67b4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # 定义模型的层次\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # 第一层，全连接层\n",
    "        self.fc2 = nn.Linear(128, 10)  # 第二层，输出层，10个类别\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 前向传播定义\n",
    "        x = torch.flatten(x, 1)  # 展平输入图片 (batch_size, 28, 28) -> (batch_size, 28*28)\n",
    "        x = torch.relu(self.fc1(x))  # 通过第一层并应用ReLU激活函数\n",
    "        x = self.fc2(x)  # 通过第二层得到输出\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b7f3a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:\n",
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Model parameters:\n",
      "torch.Size([128, 784])\n",
      "torch.Size([128])\n",
      "torch.Size([10, 128])\n",
      "torch.Size([10])\n",
      "fc1.weight: torch.Size([128, 784])\n",
      "fc1.bias: torch.Size([128])\n",
      "fc2.weight: torch.Size([10, 128])\n",
      "fc2.bias: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建模型实例\n",
    "model = SimpleNN()\n",
    "\n",
    "# 打印模型结构\n",
    "print(\"Model structure:\")\n",
    "print(model)\n",
    "\n",
    "# 查看模型参数\n",
    "print(\"\\nModel parameters:\")\n",
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4001a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation outputs: tensor([[-7.3347e-02, -1.1473e-01,  3.2109e-01,  2.4325e-01, -1.7589e-01,\n",
      "         -1.3836e-01, -5.6278e-02,  7.3760e-02,  1.0805e-01,  1.1136e-01],\n",
      "        [-1.7091e-01, -9.7208e-02,  4.7650e-01, -8.6144e-02, -2.3651e-02,\n",
      "         -2.5933e-01,  2.8517e-01,  2.7950e-01,  2.5820e-01, -1.3152e-01],\n",
      "        [ 2.6194e-02, -3.1539e-01,  1.7690e-01, -3.2742e-01, -2.3170e-01,\n",
      "          1.8872e-01,  7.2235e-02, -1.9280e-01, -3.2548e-03, -1.6300e-01],\n",
      "        [-1.6516e-01, -3.7891e-01,  3.2005e-01,  1.8289e-01, -2.8213e-01,\n",
      "         -7.8919e-02,  2.3430e-01, -2.2160e-01,  2.3786e-01,  1.5226e-01],\n",
      "        [-4.1077e-01, -3.5415e-01,  1.7021e-01,  1.6924e-01, -1.1865e-01,\n",
      "         -2.6454e-01,  2.2788e-01, -1.1992e-01, -5.7016e-02, -1.5884e-01],\n",
      "        [-1.6895e-01, -1.8471e-02,  4.4429e-01,  1.6341e-01, -7.5507e-02,\n",
      "         -7.2241e-02,  7.4753e-02, -6.4325e-02,  3.1251e-01,  9.8277e-02],\n",
      "        [-1.9612e-01, -2.1791e-01,  1.9810e-01,  1.4333e-01, -2.0286e-01,\n",
      "          1.5390e-01,  4.2728e-02, -1.2167e-01,  4.3898e-01, -1.7213e-01],\n",
      "        [ 2.1704e-01, -1.8162e-02,  3.2993e-01,  1.0074e-01, -1.5802e-01,\n",
      "          3.1945e-01,  1.4184e-01,  8.3531e-02,  4.4737e-01, -2.2501e-01],\n",
      "        [-3.4318e-01,  1.8008e-01,  6.9535e-02, -8.8506e-02, -1.5670e-01,\n",
      "         -1.9930e-01, -2.1624e-01, -7.9805e-02, -1.4140e-01,  1.8050e-01],\n",
      "        [-1.7089e-01, -4.2020e-01,  1.8126e-01,  6.3327e-02, -1.8631e-01,\n",
      "          1.0844e-01,  1.9368e-01,  2.2635e-01, -4.0808e-01,  1.5261e-01],\n",
      "        [ 1.7202e-01, -2.5456e-01,  3.2388e-01, -1.2097e-02, -7.5870e-04,\n",
      "         -2.8173e-02,  2.9035e-01,  2.4657e-01, -4.4371e-02,  2.1638e-01],\n",
      "        [-3.2473e-01, -4.8492e-02,  1.0827e-01, -3.8970e-01,  1.9856e-01,\n",
      "          3.3572e-02,  5.9690e-02,  8.5615e-02,  9.2452e-02,  4.0053e-01],\n",
      "        [-2.4612e-01, -2.4631e-01,  4.0229e-01, -1.0962e-02, -1.0470e-02,\n",
      "          2.6237e-01,  2.9831e-01, -3.4156e-01,  1.3518e-01,  1.0847e-01],\n",
      "        [-1.3161e-01, -8.2772e-02,  3.7709e-01, -1.2604e-01, -3.5964e-02,\n",
      "         -2.6537e-01,  1.6230e-01,  2.2004e-01,  2.4033e-01,  1.0964e-01],\n",
      "        [-2.9661e-01,  3.1501e-02,  4.5857e-01, -9.9529e-02, -1.2941e-01,\n",
      "         -6.4393e-02,  2.3386e-01, -1.3938e-01, -2.8581e-01,  2.8111e-01],\n",
      "        [-3.1971e-01, -2.0012e-01,  2.6334e-01,  4.5853e-01, -3.2909e-01,\n",
      "         -8.8948e-04,  2.4912e-01, -1.1152e-01,  8.2162e-02,  8.0085e-02],\n",
      "        [-2.3473e-01, -4.1110e-01, -1.2130e-01,  1.7953e-01,  9.6379e-02,\n",
      "          1.2586e-01,  2.9335e-01, -1.3832e-01,  2.9073e-01, -6.9915e-02],\n",
      "        [-4.8345e-01,  1.9537e-01,  1.3150e-01, -5.3488e-02, -4.1113e-01,\n",
      "         -8.1430e-02,  4.1145e-02,  1.9701e-01,  5.2281e-03,  2.6003e-01],\n",
      "        [-2.3116e-01, -9.4605e-02, -2.0181e-01,  1.1531e-01, -3.8021e-02,\n",
      "          4.0112e-01,  3.0931e-01,  3.3453e-01,  1.2384e-01,  5.5397e-02],\n",
      "        [-2.0606e-01, -1.7924e-01,  1.2374e-01,  1.5388e-01,  1.4778e-01,\n",
      "          1.5624e-01,  8.9493e-02, -4.2695e-02,  3.3747e-01,  1.8780e-01],\n",
      "        [-2.4324e-01,  3.2890e-01,  2.6658e-01, -2.7908e-02,  1.4104e-02,\n",
      "          1.1434e-01,  2.6092e-01, -1.9260e-01,  4.0390e-01,  1.1257e-01],\n",
      "        [-8.2724e-02, -1.7382e-01,  2.9970e-01, -1.5822e-01, -3.7915e-02,\n",
      "          2.1433e-01,  2.1821e-01, -9.9126e-02,  1.6794e-01,  2.6845e-01],\n",
      "        [-2.6595e-01,  2.1347e-01,  5.9220e-01, -2.2514e-01, -1.1785e-01,\n",
      "         -2.9856e-01,  3.8448e-02, -7.6447e-02,  1.7392e-02,  1.5888e-01],\n",
      "        [-7.0071e-02, -1.1273e-01,  2.0992e-01,  1.6913e-01,  1.9728e-02,\n",
      "          2.9261e-01,  2.3185e-01, -1.7713e-02,  4.4165e-01, -1.6446e-01],\n",
      "        [-2.7453e-01,  6.7044e-02,  5.2998e-01, -6.0607e-03,  1.0748e-01,\n",
      "          3.5143e-01,  1.1452e-01, -7.9014e-02,  1.5693e-01,  1.2212e-01],\n",
      "        [-3.1913e-01, -3.5207e-01,  2.9839e-01, -2.1068e-01,  7.4355e-02,\n",
      "         -1.2385e-01,  5.0738e-02, -1.2285e-01,  7.4770e-02,  3.0218e-01],\n",
      "        [-2.4599e-01, -2.7556e-01,  2.5988e-01, -7.0907e-02, -2.4331e-01,\n",
      "          1.3386e-01,  6.1573e-01,  2.5104e-01, -1.0570e-02,  1.4925e-01],\n",
      "        [-6.0812e-02, -3.3788e-01,  1.9329e-01, -5.4339e-02, -3.9183e-01,\n",
      "          1.4672e-01,  1.2690e-01,  7.2197e-03,  7.3475e-02, -5.8479e-03],\n",
      "        [-4.8786e-01, -2.1582e-01,  2.4584e-02, -4.1890e-01, -1.8888e-01,\n",
      "         -5.6240e-02,  1.6977e-01, -3.9887e-02, -7.4371e-02,  1.6691e-01],\n",
      "        [-5.9123e-02, -3.5465e-01,  1.8009e-01,  1.0279e-01, -3.3198e-01,\n",
      "         -1.2185e-01,  8.8561e-02, -5.1976e-02,  4.2303e-01, -3.3495e-01],\n",
      "        [-4.5999e-01,  7.3126e-02,  1.3880e-01,  2.8948e-02, -2.9755e-01,\n",
      "         -8.8467e-02,  1.3467e-02, -4.6851e-01,  5.6411e-04,  4.0229e-01],\n",
      "        [-1.5107e-01, -2.4286e-01,  3.4196e-01, -2.3446e-01, -2.3527e-02,\n",
      "         -1.7459e-01,  2.6963e-01, -8.2470e-02,  2.3635e-01,  1.4259e-01]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Parameter grad: tensor([[ 0.0030,  0.0396, -0.0177,  ...,  0.0241, -0.0201,  0.0032],\n",
      "        [-0.0215, -0.0023, -0.0034,  ..., -0.0095,  0.0134,  0.0042],\n",
      "        [ 0.0467,  0.0015, -0.0283,  ...,  0.0161,  0.0270, -0.0321],\n",
      "        ...,\n",
      "        [ 0.0274,  0.0181, -0.0026,  ..., -0.0374,  0.0113,  0.0118],\n",
      "        [ 0.0074,  0.0191,  0.0372,  ..., -0.0310, -0.0066,  0.0081],\n",
      "        [ 0.0040,  0.0464, -0.0098,  ..., -0.0573,  0.0494,  0.0279]],\n",
      "       device='cuda:0')\n",
      "Parameter grad: tensor([ 0.0015,  0.0313,  0.0598,  0.0584,  0.0431, -0.0212,  0.0205,  0.0029,\n",
      "         0.0807,  0.0223,  0.0038,  0.0219,  0.0397,  0.0542,  0.0196,  0.0171,\n",
      "        -0.0392,  0.0546, -0.0043,  0.0263, -0.0012,  0.0334,  0.0010, -0.0172,\n",
      "         0.0315,  0.0040,  0.0093, -0.0015,  0.0386,  0.0303,  0.0114, -0.0054,\n",
      "         0.0064,  0.0484, -0.0433, -0.0055, -0.0461,  0.0012, -0.0024,  0.0452,\n",
      "         0.0103,  0.0151,  0.0341, -0.0027,  0.0087, -0.0279, -0.0185,  0.0231,\n",
      "        -0.0181,  0.0123, -0.0149, -0.0182,  0.0037, -0.0005,  0.0491,  0.0262,\n",
      "        -0.0294,  0.0120,  0.0326, -0.0281,  0.0149, -0.0156, -0.0200, -0.0002,\n",
      "        -0.0022, -0.0127,  0.0122,  0.0256, -0.0243,  0.0549,  0.0227,  0.0136,\n",
      "        -0.0534,  0.0150, -0.0347,  0.0220,  0.0079, -0.0009, -0.0332, -0.0064,\n",
      "        -0.0389, -0.0260,  0.0251,  0.0041, -0.0150,  0.0398, -0.0452, -0.0047,\n",
      "         0.0471,  0.0119, -0.0296, -0.0032, -0.0066, -0.0063, -0.0490,  0.0343,\n",
      "         0.0096,  0.0520,  0.0449,  0.0517, -0.0645,  0.0034,  0.0054, -0.0027,\n",
      "         0.0056, -0.0047,  0.0555,  0.0414, -0.0047,  0.0004, -0.0002,  0.0180,\n",
      "        -0.0111, -0.0051,  0.0189,  0.0130,  0.0218, -0.0225,  0.0116, -0.0060,\n",
      "        -0.0196,  0.0140, -0.0357,  0.0166,  0.0111, -0.0124,  0.0193,  0.0363],\n",
      "       device='cuda:0')\n",
      "Parameter grad: tensor([[-0.1750, -0.0540,  0.0036,  ..., -0.2002, -0.1508, -0.0707],\n",
      "        [-0.0341, -0.0517, -0.0096,  ...,  0.0317, -0.0403, -0.0520],\n",
      "        [ 0.1134,  0.0868,  0.1633,  ...,  0.1198,  0.0421,  0.0260],\n",
      "        ...,\n",
      "        [-0.0701, -0.0909, -0.1504,  ..., -0.1104, -0.1061, -0.0550],\n",
      "        [ 0.0401,  0.0514, -0.0137,  ...,  0.0903,  0.0407, -0.0819],\n",
      "        [-0.0502, -0.0457, -0.0738,  ...,  0.0400,  0.0226, -0.0219]],\n",
      "       device='cuda:0')\n",
      "Parameter grad: tensor([-0.5549, -0.2943,  0.3826,  0.3610, -0.3097, -0.0041,  0.2825, -0.2097,\n",
      "         0.2672,  0.0795], device='cuda:0')\n",
      "Parameter requires_grad: True\n",
      "Parameter requires_grad: True\n",
      "Parameter requires_grad: True\n",
      "Parameter requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 选择设备: GPU/CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 假设训练数据\n",
    "inputs = torch.randn(32, 28, 28).to(device)  # Batch size: 32, 每个输入为28x28的图片\n",
    "labels = torch.randint(0, 10, (32,)).to(device)  # 32个样本的标签，范围在0到9之间\n",
    "\n",
    "# 训练模式\n",
    "model.train()\n",
    "outputs = model(inputs)  # 前向传播\n",
    "loss = criterion(outputs, labels)  # 计算损失\n",
    "loss.backward()  # 反向传播\n",
    "\n",
    "# 在评估模式下，不会计算梯度\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "loss.backward()  # 这里不会更新参数，因为没有梯度计算\n",
    "print(\"\\nEvaluation outputs:\", outputs)\n",
    "for param in model.parameters():\n",
    "    print(\"Parameter grad:\", param.grad)\n",
    "    \n",
    "    \n",
    "    \n",
    "# model.eval()\n",
    "# for param in model.parameters():\n",
    "#     print(\"Parameter requires_grad:\", param.requires_grad)\n",
    "with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "        print(\"Parameter requires_grad:\", param.requires_grad)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cafd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: ['test.weight', 'test.bias']\n",
      "Unexpected keys: []\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "compare:\n",
    "strict=False vs strict=True\n",
    "\"\"\"\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'simple_nn.pth')\n",
    "# 加载模型\n",
    "model_loaded = SimpleNN()\n",
    "model_loaded.test = torch.nn.Linear(28 * 28, 10)  # 确保加载的模型有相同的结构\n",
    "\n",
    "missing,unexpected =model_loaded.load_state_dict(torch.load('simple_nn.pth'), strict=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b0f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "None\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangk\\AppData\\Local\\Temp\\ipykernel_17624\\1503274581.py:13: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(outputs.grad)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nCompare:\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Compare:\n",
    "- .eval()\n",
    "- with torch.no_grad()\n",
    "- .requires_grad_(False)\n",
    "\"\"\"\n",
    "model.eval()  # 评估模式\n",
    "for param in model.parameters():\n",
    "    print(param.requires_grad)\n",
    "    \n",
    "model.requires_grad_(False)  # 禁用梯度计算\n",
    "for param in model.parameters():\n",
    "    print(param.requires_grad)\n",
    "    \n",
    "model.requires_grad_(True)  # 恢复梯度计算\n",
    "    \n",
    "inputs = torch.randn(32, 28, 28).to(device,dtype = torch.float32)  # Batch size: 32, 每个输入为28x28的图片\n",
    "outputs = model(inputs)  # 前向传播\n",
    "print(outputs.grad)\n",
    "loss = torch.nn.MSELoss()(outputs,outputs*0)\n",
    "loss.backward()  # 反向传播\n",
    "for param in model.parameters():\n",
    "    print(param.requires_grad)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5394f82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 使用apply()来应用初始化\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "\n",
    "model.apply(init_weights)  # 应用权重初始化方法\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
